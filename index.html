<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/logo.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->

<!--       <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div> -->
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kevinz-01.github.io/">Kaiwen Zhou</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com.hk/citations?user=QC1kfNYAAAAJ&hl=zh-CN">Chengzhi Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://xuandongzhao.github.io/">Xuandong Zhao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://acompalas.github.io/#projects">Shreedhar Jangam</a><sup>1</sup>,
            </span>
            <span class="author-block">
           <span class="author-block">
              <a href="https://acompalas.github.io/#projects">Jayanth Srinivasa </a><sup>3</sup>,
            </span>
            <span class="author-block">

               <span class="author-block">
              <a href="https://acompalas.github.io/#projects"> Gaowen Liu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              
              <a href="https://dawnsong.io/">Dawn Song</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://eric-xw.github.io/">Xin Eric Wang</a><sup>1</sup>,
            </span>
       
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Santa Cruz,</span>
            <span class="author-block"><sup>2</sup>University of California, Berkley, </span>
             <span class="author-block"><sup>3</sup>Cisco</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--               <span class="link-block">
                <a href="https://huggingface.co/datasets/kzhou35/mssbench/tree/main"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
<!--       <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
<!--       <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2> -->
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
<!--           <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video> -->
<!--         </div>
        <div class="item item-chair-tp">
<!--           <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video> -->
<!--         </div>
        <div class="item item-shiba">
<!--           <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video> -->
<!--         </div>
        <div class="item item-fullbody"> -->
<!--           <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video> -->
<!--         </div>
        <div class="item item-blueshirt"> -->
<!--           <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video> -->
<!--         </div>
        <div class="item item-mask"> -->
<!--           <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video> -->
<!--         </div>
        <div class="item item-coffee"> -->
<!--           <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video> -->
<!--         </div>
        <div class="item item-toby"> -->
<!--           <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video> -->
<!--         </div>
      </div>
    </div>
  </div>
</section>  -->

              
<!-- <section class="section">
  <figure class="image is-centered" style="width: 65%; margin: 0 auto 1rem; text-align: center;">
    <img 
      src="./static/intro_00.png" 
      alt="image" 
      style="width: 70%; height: auto; display: block; margin: 0 auto;" 
      loading="lazy" 
    />
    <figcaption style="text-align: center;">
      We perform a multi-faceted safety analysis of large reasoning and non-reasoning models, focusing on three key aspects: (1) Comparison of performance across safety benchmarks and attacks. (2) Analysis of safety differences in reasoning and final answer. (3) Evaluation of the harmfulness of model responses.
    </figcaption>
  </figure>
</section>
 -->



<section class="section">
  <figure class="image is-centered" style="width: 60%; margin: 0 auto 1rem; text-align: center; box-sizing: border-box;">
    <img 
      src="./static/intro_00.png" 
      alt="image" 
      style="width: 105%; height: auto; display: block; margin: 0 auto; box-sizing: border-box;" 
      loading="lazy" 
    />
    <figcaption style="text-align: center; width: 100%; box-sizing: border-box; margin-top: 0.5rem;">
            We perform a multi-faceted safety analysis of large reasoning and non-reasoning models, focusing on three key aspects: (1) Comparison of performance across safety benchmarks and attacks. (2) Analysis of safety differences in reasoning and final answer. (3) Evaluation of the harmfulness of model responses.

    </figcaption>
  </figure>
</section>

 
<!-- </section> -->
<!--        <div class="columns is-centered has-text-centered" style="margin-top: 2rem;">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Research Questions and Safety Evaluation Design</h2>
      </div>
      </div> -->
        
<!-- </section> -->
<!-- <div class="columns is-centered has-text-centered" style="margin-top: 2rem;">
    <div class="column is-four-fifths">
        <h2 class="title is-3">Research Questions and Safety Evaluation Design</h2>
        <ul>
            <li>
                <img src="./static/idea.png" alt="Question 1:" style="width: 20px; height: 20px; vertical-align: middle;">
                How safe are large reasoning models when given malicious queries? Are they able to refuse to follow these queries? (Section 4)
            </li>
          
            <li>
                <img src="./static/idea.png" alt="Question 2:" style="width: 20px; height: 20px; vertical-align: middle;">
                How does enhanced reasoning ability affect the harmfulness level of the unsafe responses? (Section 5)
            </li>
          
            <li>
                <img src="./static/idea.png" alt="Question 3:" style="width: 20px; height: 20px; vertical-align: middle;">
                How safe are large reasoning models when facing adversarial attacks? (Section 6)
            </li>
          
            <li>
                <img src="./static/idea.png" alt="Question 4:" style="width: 20px; height: 20px; vertical-align: middle;">
                How do the safety risks of the thinking process in large reasoning models compare to those of the final answer? (Section 7)
            </li>
        </ul>
    </div>
</div> -->

<div class="columns is-centered has-text-centered" style="margin-top: 2rem;">
    <div class="column is-four-fifths">
        <h2 class="title is-3">Research Questions and Safety Evaluation Design</h2>
        <ul>
            <li>
                <img src="./static/idea.png" alt="Question 1:" style="width: 20px; height: 20px; vertical-align: middle;">
                How safe are large reasoning models when given malicious queries? Are they able to refuse to follow these queries? (Section 4)
            </li>
            <br>
            <li>
                <img src="./static/idea.png" alt="Question 2:" style="width: 20px; height: 20px; vertical-align: middle;">
                How does enhanced reasoning ability affect the harmfulness level of the unsafe responses? (Section 5)
            </li>
            <br>
            <li>
                <img src="./static/idea.png" alt="Question 3:" style="width: 20px; height: 20px; vertical-align: middle;">
                How safe are large reasoning models when facing adversarial attacks? (Section 6)
            </li>
            <br>
            <li>
                <img src="./static/idea.png" alt="Question 4:" style="width: 20px; height: 20px; vertical-align: middle;">
                How do the safety risks of the thinking process in large reasoning models compare to those of the final answer? (Section 7)
            </li>
        </ul>
    </div>
</div>

              
<div class="columns is-centered has-text-centered" style="margin-top: -0.5rem;">
  <div class="column is-four-fifths" style="max-width: 55%; margin: 0 auto;">
    <h2 class="title is-3">Safety Benchmarking</h2>
    <p>
    We investigate the safety performance of large reasoning models in handling malicious queries. We begin by analyzing their overall performance, and identifying a distinct safety behavior from them. Then, we analyze their behavioral patterns on selected representative datasets.

    </p>
  </div>
</div>
              

  <section class="section">
  <figure class="image is-centered" style="width: 70%; margin: 0 auto 1rem; text-align: center; box-sizing: border-box;">
    <img 
      src="./static/heatmap_new_00.png" 
      alt="image" 
      style="max-width: 90%; height: auto; display: block; margin: 0 auto; box-sizing: border-box;" 
      loading="lazy" 
    />
    <figcaption style="text-align: center; max-width: 100%; box-sizing: border-box;">
            Two safety benchmark evaluations: (A) Level-2 categorized results of the models on Air-Bench.  (B) Evaluation of the models' safety rate (\%) in the Code Interpreter Tests across different risk categories.

    </figcaption>
  </figure>
</section>


    
<div class="columns is-centered has-text-centered" style="margin-top: -0.5rem;">
  <div class="column is-four-fifths" style="max-width: 58%; margin: 0 auto;">
    <h2 class="title is-3">Response Harmfulness Level Evaluation</h2>
    <p>
      Safety classification alone is not sufficient to comprehensively assess models' safety, as not all responses classified as unsafe are equally harmful - some provide minimal information, while others offer detailed, actionable guidance that aids malicious intent. 
      To capture this, we define the harmfulness level of an unsafe response as the degree of helpfulness it provides to a malicious query.
    </p>
  </div>
</div>


<section class="section">
  <figure class="image is-centered" style="width: 56%; margin: 0 auto 1rem; text-align: center; box-sizing: border-box;">
    <img 
      src="./static/safe_00.png" 
      alt="image" 
      style="width: 100%; height: auto; display: block; margin: 0 auto; box-sizing: border-box;" 
      loading="lazy" 
    />
    <figcaption style="text-align: center; width: 100%; box-sizing: border-box; margin-top: 0.5rem;">
    Left Subfigure: The harmfulness evaluation result for two pairs of LLMs using two reward models on Air-Bench dataset. The response from reasoning models provides more help to the harmful questions.  Right Subfigure: Example of large reasoning model provides more detailed and structured responses to the malicious query compared with non-reasoning model.

    </figcaption>
  </figure>
</section>

 


    
<div class="columns is-centered has-text-centered" style="margin-top: -0.5rem;">
  <div class="column is-four-fifths" style="max-width: 54%; margin: 0 auto;">
    <h2 class="title is-3">Safety Attacking</h2>
    <p>
   This section evaluates the models' safety performance against two types of adversarial attacks: the jailbreak attack, which forces the model to respond to harmful queries, and the prompt injection attack, which aims to override the models' intended behavior or bypass restrictions.
    </p>
  </div>
</div>


<section class="section">
  <figure class="image is-centered" style="width: 56%; margin: 0 auto 1rem; text-align: center; box-sizing: border-box;">
    <img 
      src="./static/example_00.png" 
      alt="image" 
      style="width: 100%; height: auto; display: block; margin: 0 auto; box-sizing: border-box;" 
      loading="lazy" 
    />
    <figcaption style="text-align: center; width: 105%; box-sizing: border-box; margin-top: 0.5rem;">
      Three Scenarios of the R1 Model in Jailbreak: (A) Identifies safety concerns but executes the user's request unreflectively. (B) Recognizes safety issues but is misled. (C) Fails to recognize any safety concerns.
    </figcaption>
  </figure>
</section>
              

    


<div class="columns is-centered has-text-centered" style="margin-top: -0.5rem;">
  <div class="column is-four-fifths" style="max-width: 50%; margin: 0 auto;">
    <h2 class="title is-3">Thinking Process v.s. Final Answer</h2>
    <p>
      <p>We compare the safety of the thinking process from R1 models and their final answer when given harmful queries. Specifically, we take the content between <code>&lt;think&gt;</code> and <code>&lt;/think&gt;</code> from the models' output and use the same evaluation prompt to judge the safety.</p>
<p>We can observe that the safety rate of the thinking process is lower than the final answer.</p>
<p>After investigating the models' responses, we identify two main types of cases where the thinking process contains 'hidden' safety risks that are not reflected in the final answer.</p>
    </p>
  </div>
</div>

 <section class="section">
  <figure class="image is-centered" style="width: 60%; margin: 0 auto 1rem; text-align: center; box-sizing: border-box;">
    <img 
      src="./static/example2_00.png" 
      alt="image" 
      style="max-width: 70%; height: auto; display: block; margin: 0 auto; box-sizing: border-box;" 
      loading="lazy" 
    />
    <figcaption style="text-align: center; max-width: 100%; box-sizing: border-box;">
          <p>Two examples where the safety of the reasoning content is worse than the final completion.</p>
<p><b>Left</b>: The reasoning content directly provides techniques that help the malicious query.</p>
<p><b>Right</b>: The reasoning content provides safe paraphrasing techniques that are relevant to the malicious query. <span style="color:red">Red text is the potentially unsafe content.</span></p>

    </figcaption>
  </figure>
</section>
              




<!-- 固定布局的 BibTeX 部分 -->
<section class="section" id="BibTeX">
  <div class="container content" style="max-width: 800px; margin: 0 auto;">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{zhou2024multimodalsituationalsafety,
      title={Multimodal Situational Safety}, 
      author={Kaiwen Zhou and Chengzhi Liu and Xuandong Zhao and Anderson Compalas and Dawn Song and Xin Eric Wang},
      year={2024},
      eprint={2410.06172},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.06172}, 
}</code></pre>
  </div>
</section>



<!-- <section class="section">
  <div class="columns is-centered" style="margin-bottom: 10rem;">
    <!-- 左侧图片 -->
<!--     <div class="column is-half" style="text-align: center;">
      <figure class="image">
        <img 
          src="./static/agent_chat.png" 
          srcset="./static/agent_chat-small.png 600w, ./static/agent_chat-medium.png 1200w, ./static/agent_chat-large.png 2000w" 
          sizes="(max-width: 600px) 600px, (max-width: 1200px) 1200px, 100vw"
          alt="image" 
          style="width: 100%; height: auto;" 
          loading="lazy"
        />
    </div> -->
    
 
<!--     <div class="column is-half" style="text-align: center;">
      <figure class="image">
        <img 
          src="./static/agent_embodied.png" 
          srcset="./static/agent_embodied-small.png 600w, ./static/agent_embodied-medium.png 1200w, ./static/agent_embodied-large.png 2000w" 
          sizes="(max-width: 600px) 600px, (max-width: 1200px) 1200px, 100vw"
          alt="image" 
          style="width: 100%; height: auto;" 
          loading="lazy"
        />
    </div>
  </div>
  <figcaption style="text-align: center;">
    MLLM's performance on our benchmark with three reasoning settings. Base setting: without explicit safety reasoning. 1 step CoT: MLLMs reasoning the safety of user query and generating response at one step. Multi-agent: our designed multi-agent pipeline. The results show that the multi-agent pipeline improves performance in most cases.
  </figcaption>
  </figure>
  </div>
</section> 


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
